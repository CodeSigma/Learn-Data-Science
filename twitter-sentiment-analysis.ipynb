{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Twitter Sentiment Analysis","metadata":{"_uuid":"92b885dd147dac19bd0a33db3cd0da100bd5bc23"}},{"cell_type":"code","source":"!pip install gensim --upgrade\n!pip install keras --upgrade\n!pip install pandas --upgrade","metadata":{"_uuid":"70282bce8b42a51e4d44f2c7d85c4ca9567b0fd4","trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gensim\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/92/787d4c9050d4669f9103d37081b34b06c277b3997f440e53a80ef8128082/gensim-4.0.1-cp36-cp36m-manylinux1_x86_64.whl (23.9MB)\n\u001b[K    100% |████████████████████████████████| 23.9MB 1.1MB/s ta 0:00:011   85% |███████████████████████████▍    | 20.5MB 3.3MB/s eta 0:00:02\n\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.3 in /opt/conda/lib/python3.6/site-packages (from gensim) (1.15.4)\nRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /opt/conda/lib/python3.6/site-packages (from gensim) (0.6)\nRequirement already satisfied, skipping upgrade: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim) (1.1.0)\nCollecting smart-open>=1.8.1 (from gensim)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/36/5f7cdd039b2a49636aa098145a3f233601d4580805ccf19819743bd7dad1/smart_open-5.0.0-py3-none-any.whl (56kB)\n\u001b[K    100% |████████████████████████████████| 61kB 2.5MB/s ta 0:00:01\n\u001b[?25hInstalling collected packages: smart-open, gensim\n  Found existing installation: smart-open 1.7.1\n    Uninstalling smart-open-1.7.1:\n      Successfully uninstalled smart-open-1.7.1\n  Found existing installation: gensim 3.6.0\n    Uninstalling gensim-3.6.0:\n      Successfully uninstalled gensim-3.6.0\nSuccessfully installed gensim-4.0.1 smart-open-5.0.0\n\u001b[33mYou are using pip version 18.1, however version 21.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\nCollecting keras\n  Downloading https://files.pythonhosted.org/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl\nRequirement already satisfied, skipping upgrade: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras) (1.15.4)\nRequirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.6/site-packages (from keras) (2.8.0)\nRequirement already satisfied, skipping upgrade: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras) (3.12)\nRequirement already satisfied, skipping upgrade: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras) (1.1.0)\nRequirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.6/site-packages (from h5py->keras) (1.11.0)\nInstalling collected packages: keras\n  Found existing installation: Keras 2.2.4\n    Uninstalling Keras-2.2.4:\n      Successfully uninstalled Keras-2.2.4\nSuccessfully installed keras-2.4.3\n\u001b[33mYou are using pip version 18.1, however version 21.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\nCollecting pandas\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/e2/00cacecafbab071c787019f00ad84ca3185952f6bb9bca9550ed83870d4d/pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5MB)\n\u001b[K    100% |████████████████████████████████| 9.5MB 3.3MB/s ta 0:00:01    34% |██████████▉                     | 3.2MB 4.9MB/s eta 0:00:02\n\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.15.4 in /opt/conda/lib/python3.6/site-packages (from pandas) (1.15.4)\nCollecting python-dateutil>=2.7.3 (from pandas)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n\u001b[K    100% |████████████████████████████████| 235kB 8.9MB/s ta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas) (2018.4)\nRequirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.11.0)\nInstalling collected packages: python-dateutil, pandas\n  Found existing installation: python-dateutil 2.6.0\n    Uninstalling python-dateutil-2.6.0:\n      Successfully uninstalled python-dateutil-2.6.0\n  Found existing installation: pandas 0.23.4\n    Uninstalling pandas-0.23.4:\n      Successfully uninstalled pandas-0.23.4\nSuccessfully installed pandas-1.1.5 python-dateutil-2.8.1\n\u001b[33mYou are using pip version 18.1, however version 21.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tensorflow --upgrade","metadata":{"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting tensorflow\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n\u001b[K    100% |████████████████████████████████| 109.2MB 467kB/s eta 0:00:01   18% |██████                          | 20.3MB 17.1MB/s eta 0:00:06    19% |██████▏                         | 21.0MB 16.9MB/s eta 0:00:06    19% |██████▍                         | 21.8MB 18.0MB/s eta 0:00:05    22% |███████                         | 24.2MB 19.8MB/s eta 0:00:05    22% |███████▎                        | 25.0MB 13.0MB/s eta 0:00:07\n\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.0.6)\nRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.6.1)\nRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.0.5)\nRequirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.11.0)\nCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n\u001b[K    100% |████████████████████████████████| 491kB 12.7MB/s ta 0:00:01\n\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n\u001b[K    100% |████████████████████████████████| 3.2MB 10.0MB/s ta 0:00:01\n\u001b[?25hCollecting absl-py>=0.7.0 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/c9/ef0fae29182d7a867d203f0eff8296b60da92098cc41db33a434f4be84bf/absl_py-0.12.0-py3-none-any.whl (129kB)\n\u001b[K    100% |████████████████████████████████| 133kB 15.2MB/s ta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.17.0)\nRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.15.4)\nRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.31.1)\nRequirement already satisfied, skipping upgrade: astor>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.7.1)\nCollecting wrapt>=1.11.1 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/82/f7/e43cefbe88c5fd371f4cf0cf5eb3feccd07515af9fd6cf7dbf1d1793a797/wrapt-1.12.1.tar.gz\nRequirement already satisfied, skipping upgrade: gast>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.2.0)\nCollecting google-pasta>=0.1.6 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n\u001b[K    100% |████████████████████████████████| 61kB 19.7MB/s ta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\nRequirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow) (39.1.0)\nRequirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.14.1)\nRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.0.1)\nBuilding wheels for collected packages: wrapt\n  Running setup.py bdist_wheel for wrapt ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b1/c2/ed/d62208260edbd3fa7156545c00ef966f45f2063d0a84f8208a\nSuccessfully built wrapt\n\u001b[31mthinc 6.12.0 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.12.1 which is incompatible.\u001b[0m\n\u001b[31mtensorboard 1.14.0 has requirement setuptools>=41.0.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\nInstalling collected packages: tensorflow-estimator, absl-py, tensorboard, wrapt, google-pasta, tensorflow\n  Found existing installation: absl-py 0.6.1\n    Uninstalling absl-py-0.6.1:\n      Successfully uninstalled absl-py-0.6.1\n  Found existing installation: tensorboard 1.10.0\n    Uninstalling tensorboard-1.10.0:\n      Successfully uninstalled tensorboard-1.10.0\n  Found existing installation: wrapt 1.10.11\n\u001b[31mCannot uninstall 'wrapt'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n\u001b[33mYou are using pip version 18.1, however version 21.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# DataFrame\nimport pandas as pd\n\n# Matplot\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Scikit-learn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.manifold import TSNE\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\nfrom keras import utils\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\n# nltk\nimport nltk\nfrom nltk.corpus import stopwords\nfrom  nltk.stem import SnowballStemmer\n\n# Word2vec\nimport gensim\n\n# Utility\nimport re\nimport numpy as np\nimport os\nfrom collections import Counter\nimport logging\nimport time\nimport pickle\nimport itertools\n\n# Set log\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)","metadata":{"_uuid":"303e72966af732ddef0bd8108a321095314e44af","trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-af6c106bdc6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     raise ImportError(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"],"ename":"ImportError","evalue":"Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`","output_type":"error"}]},{"cell_type":"code","source":"nltk.download('stopwords')","metadata":{"_uuid":"35e1a89dead5fd160e4c9a024a21d2e569fc89ff","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Settings","metadata":{"_uuid":"e8b01a07df001e4abcc745900336c4db06e455f3"}},{"cell_type":"code","source":"# DATASET\nDATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\nDATASET_ENCODING = \"ISO-8859-1\"\nTRAIN_SIZE = 0.8\n\n# TEXT CLENAING\nTEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n\n# WORD2VEC \nW2V_SIZE = 300\nW2V_WINDOW = 7\nW2V_EPOCH = 32\nW2V_MIN_COUNT = 10\n\n# KERAS\nSEQUENCE_LENGTH = 300\nEPOCHS = 8\nBATCH_SIZE = 1024\n\n# SENTIMENT\nPOSITIVE = \"POSITIVE\"\nNEGATIVE = \"NEGATIVE\"\nNEUTRAL = \"NEUTRAL\"\nSENTIMENT_THRESHOLDS = (0.4, 0.7)\n\n# EXPORT\nKERAS_MODEL = \"model.h5\"\nWORD2VEC_MODEL = \"model.w2v\"\nTOKENIZER_MODEL = \"tokenizer.pkl\"\nENCODER_MODEL = \"encoder.pkl\"","metadata":{"_uuid":"180f0dd2a95419e4602b5c0229822b0111c826f6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Read Dataset","metadata":{"_uuid":"1c3beecc618be68480b3d4f0de08d9d863da1dc1"}},{"cell_type":"markdown","source":"### Dataset details\n* **target**: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n* **ids**: The id of the tweet ( 2087)\n* **date**: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n* **flag**: The query (lyx). If there is no query, then this value is NO_QUERY.\n* **user**: the user that tweeted (robotickilldozr)\n* **text**: the text of the tweet (Lyx is cool)","metadata":{"_uuid":"563b3c44f1092dba0b853747b098e00509098cca"}},{"cell_type":"code","source":"dataset_filename = os.listdir(\"../input\")[0]\ndataset_path = os.path.join(\"..\",\"input\",dataset_filename)\nprint(\"Open file:\", dataset_path)\ndf = pd.read_csv(dataset_path, encoding =DATASET_ENCODING , names=DATASET_COLUMNS)","metadata":{"_uuid":"bba8f91cd70de4f5ea0fb0870ae2029b6e3dcc24","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Dataset size:\", len(df))","metadata":{"_uuid":"936d499c00c4f1648bc16ca9d283c3b39be7fb10","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"_uuid":"7486ed895b813c5246f97b31b6162b0f65ff763b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Map target label to String\n* **0** -> **NEGATIVE**\n* **2** -> **NEUTRAL**\n* **4** -> **POSITIVE**","metadata":{"_uuid":"3f9a7bb129e184967b13261fb5d253af451c75c5"}},{"cell_type":"code","source":"decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\ndef decode_sentiment(label):\n    return decode_map[int(label)]","metadata":{"_uuid":"14074b59106cb9550440839e48b832223fc9502f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf.target = df.target.apply(lambda x: decode_sentiment(x))","metadata":{"_uuid":"4449d473187f647a195a6ac6986b009da32a7f4b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_cnt = Counter(df.target)\n\nplt.figure(figsize=(16,8))\nplt.bar(target_cnt.keys(), target_cnt.values())\nplt.title(\"Dataset labels distribuition\")","metadata":{"_uuid":"19eb327803192f31cce3512aacb232f4d6b38715","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pre-Process dataset","metadata":{"_uuid":"4329b1573518b03e497213efa7676220734ebb4b"}},{"cell_type":"code","source":"stop_words = stopwords.words(\"english\")\nstemmer = SnowballStemmer(\"english\")","metadata":{"_uuid":"8aeee8b7b9ea11b749c7f91cd4787a7b50ed1a91","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(text, stem=False):\n    # Remove link,user and special characters\n    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n    tokens = []\n    for token in text.split():\n        if token not in stop_words:\n            if stem:\n                tokens.append(stemmer.stem(token))\n            else:\n                tokens.append(token)\n    return \" \".join(tokens)","metadata":{"_uuid":"649ebcb97969b9ac4301138783704bb3d7846a49","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf.text = df.text.apply(lambda x: preprocess(x))","metadata":{"_uuid":"f7f3e77ab9291d14687c49e71ba9b2b1e3323432","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split train and test","metadata":{"_uuid":"f5f9714a8507409bbe780eebf2855a33e8e6ba37","trusted":true}},{"cell_type":"code","source":"df_train, df_test = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=42)\nprint(\"TRAIN size:\", len(df_train))\nprint(\"TEST size:\", len(df_test))","metadata":{"_uuid":"d2b1179c968e3f3910c790ecf0c5b2cbb34b0e68","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Word2Vec ","metadata":{"_uuid":"f08a28aab2c3d16d8b9681a7d5d07587153a1cd6"}},{"cell_type":"code","source":"%%time\ndocuments = [_text.split() for _text in df_train.text] ","metadata":{"_uuid":"2461bf564de1b4414841933d0c1d1bee5f5cc5a6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n                                            window=W2V_WINDOW, \n                                            min_count=W2V_MIN_COUNT, \n                                            workers=8)","metadata":{"_uuid":"8e19b9f25801ba86420decc266d2b3e6fb44f1ea","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w2v_model.build_vocab(documents)","metadata":{"_uuid":"58d655af07653c594bec6bebcfb302a973b0ad9c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = w2v_model.wv.vocab.keys()\nvocab_size = len(words)\nprint(\"Vocab size\", vocab_size)","metadata":{"_uuid":"72a5628ca81fd4b8983c12d93ae0bf950b86b6ae","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nw2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)","metadata":{"_uuid":"68c3e4a5ba07cac3dee67f78ecdd1404c7f83f14","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w2v_model.most_similar(\"love\")","metadata":{"_uuid":"27cc2651c74227115d8bfd8c40e5618048e05edd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tokenize Text","metadata":{"_uuid":"e13563644468037258598637b49373ca96b9b879"}},{"cell_type":"code","source":"%%time\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(df_train.text)\n\nvocab_size = len(tokenizer.word_index) + 1\nprint(\"Total words\", vocab_size)","metadata":{"_uuid":"6852bc709a7cd20173cbeeb218505078f8f37c57","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nx_train = pad_sequences(tokenizer.texts_to_sequences(df_train.text), maxlen=SEQUENCE_LENGTH)\nx_test = pad_sequences(tokenizer.texts_to_sequences(df_test.text), maxlen=SEQUENCE_LENGTH)","metadata":{"_uuid":"45de439df3015030c71f84c2d170346936a1d68f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label Encoder ","metadata":{"_uuid":"03b35903fc6260e190d6928d240ef7432de117fc"}},{"cell_type":"code","source":"labels = df_train.target.unique().tolist()\nlabels.append(NEUTRAL)\nlabels","metadata":{"_uuid":"33676e0efa39e97d89bd650b8b4eae933a22fbf0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\nencoder.fit(df_train.target.tolist())\n\ny_train = encoder.transform(df_train.target.tolist())\ny_test = encoder.transform(df_test.target.tolist())\n\ny_train = y_train.reshape(-1,1)\ny_test = y_test.reshape(-1,1)\n\nprint(\"y_train\",y_train.shape)\nprint(\"y_test\",y_test.shape)","metadata":{"_uuid":"04239a9bef76e7922fd86098a5601dfde8ee4665","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"x_train\", x_train.shape)\nprint(\"y_train\", y_train.shape)\nprint()\nprint(\"x_test\", x_test.shape)\nprint(\"y_test\", y_test.shape)","metadata":{"_uuid":"04299c886911ca135583ab64878f213939a2990c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[:10]","metadata":{"_uuid":"232533fb27b7be99d9b8c2f8fb22c9c6bf121a6f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Embedding layer","metadata":{"_uuid":"233c0ea94055a03e2e7df3e2a13d036ec963484f"}},{"cell_type":"code","source":"embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\nfor word, i in tokenizer.word_index.items():\n  if word in w2v_model.wv:\n    embedding_matrix[i] = w2v_model.wv[word]\nprint(embedding_matrix.shape)","metadata":{"_uuid":"9ab488374b59e3f30f8b1ea92767d853c4846bac","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)","metadata":{"_uuid":"833279d91e4286065968237fb5f2a0c2dd4d246c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build Model","metadata":{"_uuid":"b299ef78f94c2085942c993a2d58753a7476305a"}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(embedding_layer)\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()","metadata":{"_uuid":"e775ef4f1b74e6412457181383c39f2df554ef3f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compile model","metadata":{"_uuid":"28d22eafd0c7d798dcf3d742bc92fb8577939e6c"}},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer=\"adam\",\n              metrics=['accuracy'])","metadata":{"_uuid":"1331e08d590bb2aa2033706c8faca217afc0f1c3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Callbacks","metadata":{"_uuid":"c7733127cb8b380e0c807268903bf4d03ef92542"}},{"cell_type":"code","source":"callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]","metadata":{"_uuid":"a688df590386f5748da6fe00b01904fe6c71619e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train","metadata":{"_uuid":"8d0873633dd49179c8cae17377641b97d323ef3b"}},{"cell_type":"code","source":"%%time\nhistory = model.fit(x_train, y_train,\n                    batch_size=BATCH_SIZE,\n                    epochs=EPOCHS,\n                    validation_split=0.1,\n                    verbose=1,\n                    callbacks=callbacks)","metadata":{"_uuid":"2b659d390c6577dc5cdb6b6297934279b4e801d5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate","metadata":{"_uuid":"267258196d96796ac69a7b8c466314bcf5d6ee42"}},{"cell_type":"code","source":"%%time\nscore = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\nprint()\nprint(\"ACCURACY:\",score[1])\nprint(\"LOSS:\",score[0])","metadata":{"_uuid":"98ecd8f1b8b74594c3ea775dd68a094e92458022","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"_uuid":"40c72cd1e9d6c4fd799cbba7c813765ac4039dfc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict","metadata":{"_uuid":"6bdfc0f6a6af5bebc0271d83dd7432c91001409b"}},{"cell_type":"code","source":"def decode_sentiment(score, include_neutral=True):\n    if include_neutral:        \n        label = NEUTRAL\n        if score <= SENTIMENT_THRESHOLDS[0]:\n            label = NEGATIVE\n        elif score >= SENTIMENT_THRESHOLDS[1]:\n            label = POSITIVE\n\n        return label\n    else:\n        return NEGATIVE if score < 0.5 else POSITIVE","metadata":{"_uuid":"f0b0fa3d4b1bb14b3f5e3d169a369f3ebef29ae1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(text, include_neutral=True):\n    start_at = time.time()\n    # Tokenize text\n    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n    # Predict\n    score = model.predict([x_test])[0]\n    # Decode sentiment\n    label = decode_sentiment(score, include_neutral=include_neutral)\n\n    return {\"label\": label, \"score\": float(score),\n       \"elapsed_time\": time.time()-start_at}  ","metadata":{"_uuid":"ed4086d651f2f8cbed11d3c909a8873607d29a06","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(\"I love the music\")","metadata":{"_uuid":"ca38b1e6c9b5acfed7467de2cf02a78333108872","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(\"I hate the rain\")","metadata":{"_uuid":"0e5fe647533be0148850de349fea6ef6f71303d1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(\"i don't know what i'm doing\")","metadata":{"_uuid":"37064dffcc8920d34ccd54fac7c8b50e583a8269","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion Matrix","metadata":{"_uuid":"3ee72e47f84b6dbc32e02a783de5ec1661f157e1"}},{"cell_type":"code","source":"%%time\ny_pred_1d = []\ny_test_1d = list(df_test.target)\nscores = model.predict(x_test, verbose=1, batch_size=8000)\ny_pred_1d = [decode_sentiment(score, include_neutral=False) for score in scores]","metadata":{"_uuid":"0e920173eb05f04aecdd735bc5dff0f5be5f8d15","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=30)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90, fontsize=22)\n    plt.yticks(tick_marks, classes, fontsize=22)\n\n    fmt = '.2f'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label', fontsize=25)\n    plt.xlabel('Predicted label', fontsize=25)","metadata":{"_uuid":"b3575191bb425ab871f3f41e83812ee84bb7e595","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ncnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\nplt.figure(figsize=(12,12))\nplot_confusion_matrix(cnf_matrix, classes=df_train.target.unique(), title=\"Confusion matrix\")\nplt.show()","metadata":{"_uuid":"a57dc6f6211c144491a70f533225edfa95a2dc66","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification Report","metadata":{"_uuid":"e23b957348dcc084249d3cc7538b972da471c2cd"}},{"cell_type":"code","source":"print(classification_report(y_test_1d, y_pred_1d))","metadata":{"_uuid":"a7fe05b7caa1c984ff1deb0be2f7c6bc043df9f5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy Score","metadata":{"_uuid":"4eb300f0c6693a618587c7dcf32f77f5416cbfb9"}},{"cell_type":"code","source":"accuracy_score(y_test_1d, y_pred_1d)","metadata":{"_uuid":"5cf76e6e09f8a60ed25947932b94c772eda44d23","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save model","metadata":{"_uuid":"4f014c32f3833db282e1a075c526604f34e3158c"}},{"cell_type":"code","source":"model.save(KERAS_MODEL)\nw2v_model.save(WORD2VEC_MODEL)\npickle.dump(tokenizer, open(TOKENIZER_MODEL, \"wb\"), protocol=0)\npickle.dump(encoder, open(ENCODER_MODEL, \"wb\"), protocol=0)","metadata":{"_uuid":"3b2b3ad5b592977b404acfa1c9ad303a62837255","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"cc363c54782894757f5ea8820c6a170f2e16ef93","trusted":true},"execution_count":null,"outputs":[]}]}